{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDm-mY0rcspV",
        "outputId": "f6e4a7b2-8ccc-443f-8a8d-b27485128cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.5.0+cu118\n",
            "Uninstalling torch-2.5.0+cu118:\n",
            "  Successfully uninstalled torch-2.5.0+cu118\n",
            "Found existing installation: torchvision 0.20.0+cu118\n",
            "Uninstalling torchvision-0.20.0+cu118:\n",
            "  Successfully uninstalled torchvision-0.20.0+cu118\n",
            "Found existing installation: torchaudio 2.5.0+cu118\n",
            "Uninstalling torchaudio-2.5.0+cu118:\n",
            "  Successfully uninstalled torchaudio-2.5.0+cu118\n",
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-spline-conv as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torch-geometric 2.6.1\n",
            "Uninstalling torch-geometric-2.6.1:\n",
            "  Successfully uninstalled torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y torch torchvision torchaudio torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nwxg2yEGcz3e",
        "outputId": "64abcbb1-b9f6-416d-a58f-d9e739a27340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.1.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp39-cp39-linux_x86_64.whl (2325.9 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:06\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp39-cp39-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp39-cp39-linux_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch==2.1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch==2.1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch==2.1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch==2.1.0) (2024.9.0)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:02\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torchvision) (1.26.4)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp39-cp39-linux_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.20.0%2Bcu118-cp39-cp39-linux_x86_64.whl (6.5 MB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.1%2Bcu118-cp39-cp39-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp39-cp39-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.1%2Bcu118-cp39-cp39-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.0%2Bcu118-cp39-cp39-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.2%2Bcu118-cp39-cp39-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hINFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.1%2Bcu118-cp39-cp39-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.0%2Bcu118-cp39-cp39-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torchvision) (2.32.3)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.2%2Bcu118-cp39-cp39-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.1%2Bcu118-cp39-cp39-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp39-cp39-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torchvision) (11.0.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.5.0%2Bcu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.1%2Bcu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.1%2Bcu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.0%2Bcu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.2%2Bcu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hINFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.1%2Bcu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.0%2Bcu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.2%2Bcu118-cp39-cp39-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.1%2Bcu118-cp39-cp39-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp39-cp39-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from jinja2->torch==2.1.0) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from requests->torchvision) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from requests->torchvision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from requests->torchvision) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from requests->torchvision) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Installing collected packages: triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "Successfully installed torch-2.1.0+cu118 torchaudio-2.1.0+cu118 torchvision-0.16.0+cu118 triton-2.1.0\n"
          ]
        }
      ],
      "source": [
        "# pip install torch==2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  # For CPU\n",
        "!pip install torch==2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # For GPU\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nSreu0Dc5lU",
        "outputId": "c3ab1ffc-492e-44f8-e7c3-a3f7f4cf9558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_scatter-2.1.2%2Bpt21cu118-cp39-cp39-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_sparse-0.6.18%2Bpt21cu118-cp39-cp39-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_cluster-1.6.3%2Bpt21cu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt21cu118-cp39-cp39-linux_x86_64.whl (888 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.3/888.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Requirement already satisfied: scipy in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: aiohttp in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch-geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch-geometric) (2024.9.0)\n",
            "Requirement already satisfied: jinja2 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch-geometric) (6.0.0)\n",
            "Requirement already satisfied: pyparsing in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from aiohttp->torch-geometric) (1.15.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from jinja2->torch-geometric) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n",
            "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
            "Successfully installed torch-cluster-1.6.3+pt21cu118 torch-geometric-2.6.1 torch-scatter-2.1.2+pt21cu118 torch-sparse-0.6.18+pt21cu118 torch-spline-conv-1.2.2+pt21cu118\n"
          ]
        }
      ],
      "source": [
        "# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from seaborn) (2.2.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from seaborn) (3.9.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.20.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Installing collected packages: seaborn\n",
            "Successfully installed seaborn-0.13.2\n"
          ]
        }
      ],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyi5EYKtcRpy",
        "outputId": "7be163b7-c6d8-4fa0-a2c4-a0774f0dc722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jIL-UeJnQ5F1",
        "outputId": "2467b040-0a40-472c-bccd-f196acab2026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch version: 2.1.0+cu118\n",
            "Torch Geometric version: 2.6.1\n",
            "CUDA Available: True\n",
            "Torch Cluster is installed correctly!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "import torch_cluster\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"Torch Geometric version:\", torch_geometric.__version__)\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"Torch Cluster is installed correctly!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee4Cawi6dTlx",
        "outputId": "b582be19-edcd-4b32-8af2-82c783f169f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.26.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EZJg5D1dZ-x",
        "outputId": "890fbaf9-9967-4b3a-b81e-0e0695ee93b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumPy version: 1.26.4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tGBGyE9-0DtX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import DynamicEdgeConv, GATConv, global_max_pool\n",
        "from torch_geometric.data import Data, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpQWrTK8cO2W",
        "outputId": "e73d9c25-7986-49cd-91b2-4ed5d8dcb8b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['X', 'y']\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "file_path = (\"/home/ujjwal/Dashboard/GAN on HEP/GNN on HEP/QG_jets.npz\")\n",
        "data = np.load(file_path, allow_pickle=True)\n",
        "\n",
        "print(data.files)\n",
        "# train_data = data['training_input']\n",
        "# test_data = data['test_input']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meUhoPNZ0fnI",
        "outputId": "bc80e499-1530-4715-a8ec-27542d8789cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((100000, 139, 4), (100000,))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['X'].shape, data['y'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4iDoFWN-0Oln"
      },
      "outputs": [],
      "source": [
        "# Extract training and test data\n",
        "X = data['X']\n",
        "y = data['y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndwIkoXA0ZJg",
        "outputId": "f2b11325-32a0-458c-c45b-999056d3c777"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(139, 4)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVFYZvjV0_yF",
        "outputId": "612caa59-2623-4cb5-cd58-dbbccef8efaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 1., 1., ..., 1., 0., 0.])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[:-5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PvHNCIr01Kfg"
      },
      "outputs": [],
      "source": [
        "_, X_new, _, y_new = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "D0KgQ1I0RIs0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlaUaziB24xR",
        "outputId": "ef45e971-177f-4435-a3da-91b81fd7c693"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((16000, 139, 4), (4000, 139, 4), (16000,), (4000,))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7JE2LraIe3B8",
        "outputId": "24a3ac15-5f51-4211-a289-65911638da89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 8.19062772e-02,  7.13226663e-01,  2.65543418e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 1.49909908e-01,  9.02892302e-01,  2.88856597e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 6.13477869e-01,  8.47353599e-01,  2.84087708e+00,\n",
              "         1.30000000e+02],\n",
              "       [ 1.05701503e+00,  5.76321842e-01,  2.80262170e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 1.86652044e+00,  7.51513249e-01,  2.98552541e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 5.90934964e-01,  4.73384081e-01,  2.89736364e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 3.90991255e+00,  5.26869874e-01,  3.01202014e+00,\n",
              "         2.11000000e+02],\n",
              "       [ 2.11268998e+01,  5.92743577e-01,  3.04135006e+00,\n",
              "        -2.11000000e+02],\n",
              "       [ 4.01586158e+00,  5.41922258e-01,  2.95194321e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 9.60884753e+00,  6.37358826e-01,  3.02288679e+00,\n",
              "         2.11000000e+02],\n",
              "       [ 8.50202136e+00,  6.12128632e-01,  3.02934779e+00,\n",
              "        -2.11000000e+02],\n",
              "       [ 1.29459461e+01,  6.25134101e-01,  2.92785380e+00,\n",
              "        -2.11000000e+02],\n",
              "       [ 5.69993287e+00,  6.18221104e-01,  2.93065091e+00,\n",
              "         2.11000000e+02],\n",
              "       [ 2.78700107e+01,  6.11906906e-01,  2.93919635e+00,\n",
              "         2.11200000e+03],\n",
              "       [ 3.77218054e+00,  5.85270856e-01,  2.94036233e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 2.30941438e+01,  6.35527520e-01,  2.98218672e+00,\n",
              "        -2.11000000e+02],\n",
              "       [ 3.36191541e+01,  6.21012450e-01,  2.95065677e+00,\n",
              "         2.11000000e+02],\n",
              "       [ 1.23742918e+01,  6.25310546e-01,  2.99686772e+00,\n",
              "         3.21000000e+02],\n",
              "       [ 3.27115256e+00,  5.98090238e-01,  2.94617922e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 2.83267436e+00,  6.17529403e-01,  2.96613891e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 2.75973559e+01,  5.95227429e-01,  2.95865948e+00,\n",
              "        -2.11000000e+02],\n",
              "       [ 2.93024327e+00,  6.01994010e-01,  2.97072011e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 6.41565259e+00,  6.03481829e-01,  2.97004392e+00,\n",
              "         2.11000000e+02],\n",
              "       [ 3.05471500e+01,  6.06902752e-01,  2.97927698e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 2.67464723e+01,  6.06882560e-01,  2.97581664e+00,\n",
              "        -2.11200000e+03],\n",
              "       [ 3.77382272e+01,  6.10269080e-01,  2.97716214e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 6.91562015e+00,  5.94203550e-01,  2.96486170e+00,\n",
              "        -2.11000000e+02],\n",
              "       [ 1.16516747e+01,  5.79564309e-01,  2.96519511e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 3.27968075e+00,  5.68810050e-01,  2.97517814e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 3.13693544e+00,  5.93677172e-01,  2.97205891e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 1.17053392e+01,  5.85290168e-01,  2.97406487e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 3.35883460e+00,  5.79221789e-01,  2.99944312e+00,\n",
              "         2.11000000e+02],\n",
              "       [ 1.05370697e+01,  5.98101409e-01,  2.99238759e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 3.59417614e+00,  5.92456284e-01,  2.99360268e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 9.49843505e+00,  5.84704307e-01,  2.99398603e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 5.34139081e+01,  5.90727488e-01,  2.98982826e+00,\n",
              "        -2.11000000e+02],\n",
              "       [ 1.49482144e+01,  5.80635534e-01,  2.98683946e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 4.54161660e+01,  5.84036861e-01,  2.98770862e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 4.06035692e+01,  5.86152325e-01,  2.98538376e+00,\n",
              "         2.20000000e+01],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeakQzOj4vqz"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The considerations we take when converting the point-cloud dataset into a graph structure, where individual points become nodes and relationships between them become edges.\n",
        "\n",
        "When projecting each point-cloud sample into a graph, every point is treated as a node. In this dataset, each sample contains 139 points with 4 features each (for example, spatial coordinates and other physical properties\n",
        "\n",
        "). This configuration ensures that the graph’s node features faithfully capture all the measured attributes of the original point-cloud.\n",
        "\n",
        "A principal design decision is how to define the connectivity between nodes. One effective approach is to compute all pairwise connections (using a method like torch.combinations) to generate a fully connected graph. While this means that every node is theoretically linked to every other node, models such as DynamicEdgeConv can then dynamically select and focus on the k-nearest neighbors (with a preset value like k = 8) during message passing. This strategy preserves comprehensive interaction possibilities while allowing the network to learn localized patterns without the computational burden of a naive full connectivity during every operation\n",
        "\n",
        ".\n",
        "\n",
        "Other key considerations include:\n",
        "\n",
        "    Uniformity and Consistency:\n",
        "\n",
        "    Since all samples have the same number of points (139), a single precomputed structure for the edge list can be used across the dataset. This ensures that each graph has consistent connectivity, which is beneficial for batching and for the downstream graph neural network layers.\n",
        "\n",
        "    Feature Preservation:\n",
        "\n",
        "    The node features are kept intact without reduction or masking at this stage, ensuring that every attribute—from spatial coordinates to other numerical measurements—is available for the model to learn meaningful patterns. This retention is crucial when dealing with complex physical data represented in the point-cloud.\n",
        "\n",
        "    Computational Efficiency:\n",
        "\n",
        "    Although computing a fully connected graph can be computationally heavy in very large point clouds, the moderate size of 139 nodes keeps the process tractable. Moreover, using dynamic edge selection methods within the network helps streamline computations by focusing on the most relevant neighboring relationships.\n",
        "\n",
        "    Handling Padded or Invalid Data:\n",
        "\n",
        "    The dataset sample provided includes rows that are entirely zeros. These entries likely represent padding or missing values. One must decide whether to filter these out or design the model to ignore them, ensuring that they do not adversely affect the learning of the true inter-point relationships.\n",
        "\n",
        "    Integration with Graph Neural Networks:\n",
        "    \n",
        "    Finally, the conversion process is designed with frameworks like PyTorch Geometric in mind, where each graph object includes not only the node features and edge indices but also a batch attribute. This attribute is critical for proper handling during training when multiple graphs are processed together.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ofR_FKwX5n_S"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(X, y):\n",
        "    data_list = []\n",
        "    # Precompute the edge_index for a fully connected graph on 139 nodes\n",
        "    nodes = torch.arange(X.shape[1])\n",
        "    edge_index = torch.combinations(nodes, r=2).t()  # shape: [2, num_edges]\n",
        "    for i in range(X.shape[0]):\n",
        "        # Create node features tensor\n",
        "        x = torch.tensor(X[i], dtype=torch.float)\n",
        "        y_label = torch.tensor([y[i]], dtype=torch.long)\n",
        "        data_list.append(Data(x=x, edge_index=edge_index, y=y_label))\n",
        "    return data_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6jggD1qe5PJ0"
      },
      "outputs": [],
      "source": [
        "class DGCNN(torch.nn.Module):\n",
        "    def __init__(self, k=8, input_dim=4, hidden_dim=64, output_dim=2):\n",
        "        super(DGCNN, self).__init__()\n",
        "        self.conv1 = DynamicEdgeConv(\n",
        "            torch.nn.Sequential(\n",
        "                torch.nn.Linear(2 * input_dim, hidden_dim),\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.Linear(hidden_dim, hidden_dim)\n",
        "            ),\n",
        "            k=k\n",
        "        )\n",
        "        self.conv2 = DynamicEdgeConv(\n",
        "            torch.nn.Sequential(\n",
        "                torch.nn.Linear(2 * hidden_dim, hidden_dim),\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.Linear(hidden_dim, hidden_dim)\n",
        "            ),\n",
        "            k=k\n",
        "        )\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, batch):\n",
        "        x = self.conv1(x, batch)\n",
        "        x = self.conv2(x, batch)\n",
        "        # Use global pooling to aggregate node-level features per graph\n",
        "        x = global_max_pool(x, batch)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, for GAT model we have reduced the hidden dim from 64 to 32 and heads from 8 to 4 due to limited GPU power. And for this we have to reduce the batch_size also to 2 from 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "M_JHqEXe5S4N"
      },
      "outputs": [],
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, input_dim=4, hidden_dim=32, output_dim=2, heads=4):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True)\n",
        "        self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=heads, concat=False)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        # Aggregate node features to get a graph-level embedding\n",
        "        x = global_max_pool(x, batch)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "x1HKTe905rv1"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # For GAT we pass (x, edge_index, batch), while for DGCNN we pass (x, batch)\n",
        "        if isinstance(model, GAT):\n",
        "            out = model(data.x, data.edge_index, data.batch)\n",
        "        else:\n",
        "            out = model(data.x, data.batch)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "83_f8S7928aI"
      },
      "outputs": [],
      "source": [
        "# Evaluation Function\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            # out = model(data.x, data.edge_index if isinstance(model, GAT) else data.batch)\n",
        "            \n",
        "            if isinstance(model, GAT):\n",
        "                out = model(data.x, data.edge_index, data.batch)  # Include batch\n",
        "            else:\n",
        "                out = model(data.x, data.batch)\n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += (pred == data.y).sum().item()\n",
        "            total += data.y.size(0)\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcwAnHoD532j"
      },
      "source": [
        "### Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yb5iOTzC5ty-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_9673/697128300.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
            "  y_label = torch.tensor([y[i]], dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "train_data = preprocess_data(X_train, y_train)\n",
        "test_data = preprocess_data(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q67hNKH6EYL",
        "outputId": "b65f85e3-5881-4e2e-b0f7-d51434b5d406"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ujjwal/.conda/envs/myenv/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "# Create DataLoader\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyG9l9IOcH0q"
      },
      "source": [
        "Evaluation of DCGNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3stLf5nl6jIh",
        "outputId": "f1e56923-274b-4911-a621-f831e0d3335c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.7746\n",
            "Epoch 2, Loss: 0.5409\n",
            "Epoch 3, Loss: 0.5186\n",
            "Epoch 4, Loss: 0.5254\n",
            "Epoch 5, Loss: 0.5164\n",
            "Epoch 6, Loss: 0.5019\n",
            "Epoch 7, Loss: 0.5028\n",
            "Epoch 8, Loss: 0.5033\n",
            "Epoch 9, Loss: 0.5003\n",
            "Epoch 10, Loss: 0.4918\n",
            "Test Accuracy: 0.7638\n"
          ]
        }
      ],
      "source": [
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# initialize model\n",
        "model = DGCNN().to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    loss = train(model, train_loader, optimizer, criterion, device)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = evaluate(model, test_loader, device)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDZHz_VGcDQA"
      },
      "source": [
        "Evaluation of GAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataLoader\n",
        "batch_size = 2\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NkRsUrNeeYjY",
        "outputId": "fa12f3e1-5599-43fe-9e3a-1d8f6142d25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.9775\n",
            "Epoch 2, Loss: 0.8697\n",
            "Epoch 3, Loss: 0.7862\n",
            "Epoch 4, Loss: 0.7407\n",
            "Epoch 5, Loss: 0.6981\n",
            "Epoch 6, Loss: 0.6526\n",
            "Epoch 7, Loss: 0.6412\n",
            "Epoch 8, Loss: 0.6021\n",
            "Epoch 9, Loss: 0.5917\n",
            "Epoch 10, Loss: 0.5886\n"
          ]
        }
      ],
      "source": [
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# initialize model\n",
        "model = GAT().to(device)\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    loss = train(model, train_loader, optimizer, criterion, device)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n",
        "\n",
        "# # Evaluate model\n",
        "# accuracy = evaluate(model, test_loader, device)\n",
        "# print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "rzwQK9pScCEB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GAT(\n",
              "  (conv1): GATConv(4, 32, heads=4)\n",
              "  (conv2): GATConv(128, 32, heads=4)\n",
              "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(\"cpu\")\n",
        "accuracy = evaluate(model, test_loader, \"cpu\")\n",
        "model.to(device)  # Move back to GPU for training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.6877\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparative Analysis of DGCNN vs. GAT for Jet Particle Classification\n",
        "\n",
        "## Performance Overview\n",
        "| Metric          | DGCNN            | GAT              |\n",
        "|-----------------|------------------|------------------|\n",
        "| Test Accuracy   | **76.38%**       | **68.77%**       |\n",
        "| Training Epochs | 10               | 10               |\n",
        "| Final Loss      | 0.4918           | 0.5886           |\n",
        "\n",
        "---\n",
        "\n",
        "## **DGCNN Performance (76.38%)**\n",
        "### Strengths\n",
        "- **Local Feature Learning**  \n",
        "  k-NN graph construction (k=8) effectively captures localized spatial patterns in particle jets.\n",
        "- **Robust Convergence**  \n",
        "  Stable loss reduction from 0.7746 → 0.4918 shows reliable optimization.\n",
        "- **Computational Efficiency**  \n",
        "  Handled full configuration (batch_size=32, hidden_dim=64) without memory constraints.\n",
        "\n",
        "### Limitations\n",
        "- **Fixed k Restriction**  \n",
        "  Predefined neighborhood size may miss variable-scale particle interactions.\n",
        "\n",
        "---\n",
        "\n",
        "## **GAT Performance (68.77%)**\n",
        "### Strengths\n",
        "- **Theoretical Potential**  \n",
        "  Attention mechanisms could capture non-local particle relationships.\n",
        "- **Parameter Efficiency**  \n",
        "  Achieved moderate accuracy despite severe constraints:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "batch_size = 2 # Original: 32\n",
        "\n",
        "hidden_dim = 32 # Original: 64\n",
        "\n",
        "heads = 4 # Original: 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Limitations\n",
        "- **Hardware Limitations**  \n",
        "75% reduction in attention heads critically constrained model capacity.\n",
        "- **Slow Convergence**  \n",
        "Loss decreased gradually (0.9775 → 0.5886), needing more epochs.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Comparative Insights\n",
        "| Factor               | DGCNN Advantage                          | GAT Challenge                          |\n",
        "|----------------------|------------------------------------------|----------------------------------------|\n",
        "| **Data Efficiency**  | Faster initial convergence               | Requires 2-3× more epochs              |\n",
        "| **Hardware Demands** | Efficient at batch_size=32               | Accuracy-limited at batch_size=2       |\n",
        "| **Physics Alignment**| Distance-based edges match jet topology  | Attention needs domain adaptation      |\n",
        "\n",
        "---\n",
        "\n",
        "## Recommendations\n",
        "### For DGCNN\n",
        "1. Implement adaptive k-values using learned radius queries\n",
        "2. Test hierarchical graph constructions\n",
        "\n",
        "### For GAT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Add edge pruning for zero-padded nodes\n",
        "2. Use masked attention for invalid particles\n",
        "\n",
        "### Architectural Innovation\n",
        "- Hybrid approach: DGCNN layers → GAT layers\n",
        "- Graph U-Net with attention skip connections\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "**DGCNN** currently demonstrates superior performance (76.38% vs 68.77%) under these constraints, but **GAT** shows untapped potential with proper resource allocation. Both models would benefit from explicit handling of zero-padded nodes observed in the dataset samples. Future work should focus on adaptive neighborhood selection for DGCNN and attention pattern specialization for GAT.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
